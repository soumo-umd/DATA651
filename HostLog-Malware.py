# Databricks notebook source
# MAGIC %pip install pystan==2.19.1.1
# MAGIC %pip install prophet
# MAGIC %pip install mlflow

# COMMAND ----------

import pandas as pd
aws_bucket_name = "databricks-workspace-stack-lambdazipsbucket-1mp9fb5totoc0"
mount_name = "cyberfile01"
dbutils.fs.mount("s3a://%s" % aws_bucket_name, "/mnt/%s" % mount_name)
display(dbutils.fs.ls("/mnt/%s" % mount_name))

# COMMAND ----------

df = spark.read.json("/mnt/%s/wls_day-01" % mount_name)

# COMMAND ----------

dfhl1 = df.select('LogHost', 'ProcessID', 'ProcessName', (df.Time/60 + 1).cast('int').alias("Time")). \
        where(df.EventID == 4688)

# COMMAND ----------

dfhl1.show()

# COMMAND ----------

dfhlp = dfhl1.groupBy("Time").count().toPandas()

# COMMAND ----------

dfhlp['ds'] = pd.to_datetime(dfhlp['Time'], unit='m')
dfhlp['y'] = dfhlp['count']
dfhlp.head(4)

# COMMAND ----------

from prophet import Prophet
m= Prophet()
m.fit(dfhlp)

# COMMAND ----------

future_pd = m.make_future_dataframe(
    periods=1000,
    freq='min',
    include_history=True
)
future_pd.tail(5)

# COMMAND ----------

forecast = m.predict(future_pd)

# COMMAND ----------

forecast.tail(5)

# COMMAND ----------

forecasted = forecast.merge(dfhlp, how='left', on='ds')
forecasted['anomaly'] = 0
forecasted.loc[forecasted['y'] > forecasted['yhat_upper'], 'anomaly'] = 1
forecasted.loc[forecasted['y'] < forecasted['yhat_lower'], 'anomaly'] = -1
forecasted.head(5)

# COMMAND ----------

import matplotlib.pyplot as plt
fig = plt.figure(facecolor='w', figsize=(16,6))
ax = fig.add_subplot(111)
fcst = forecasted['ds'].dt.to_pydatetime()
ax.plot(m.history['ds'].dt.to_pydatetime(), m.history['y'], 'k.')
ax.plot(forecasted[forecasted['anomaly'] !=0]['ds'], forecasted[forecasted['anomaly'] != 0]['y'], 'r.')
ax.plot(fcst, forecasted['yhat'], ls='-', c='#0072B2')
if 'cap' in forecasted:
    ax.plot(fcst_t, fcst['cap'], ls='--', c='k')
if 'floor' in forecasted:
    ax.plot(fcst, forecasted['floor'], ls='--', c='k')
if True:
    ax.fill_between(fcst, forecasted['yhat_lower'], forecasted['yhat_upper'], \
                        color='#0072B2', alpha=0.2)
ax.grid(True, which='major', c='gray', ls='-', lw=1, alpha=0.2)
ax.set_xlabel("Minute")
ax.set_ylabel("Count")
fig.tight_layout()

# COMMAND ----------

#fig1 = m.plot(forecast, xlabel="Minute", ylabel='Count')

# COMMAND ----------

m.plot_components(forecast)

# COMMAND ----------

# DBTITLE 1,Training the Time Series model on all (5) days of data
dfall = spark.read.json("/mnt/%s/wls_day-*" % mount_name)
hlall = dfall.select('LogHost', 'ProcessID', 'ProcessName', (dfall.Time/60 + 1).cast('int').alias("Time")). \
        where(dfall.EventID == 4688)
hlallp = hlall.groupBy("Time").count().toPandas()
hlallp['ds'] = pd.to_datetime(hlallp['Time'], unit='m')
hlallp['y']  = hlallp['count']

# COMMAND ----------

# DBTITLE 1,Track model training runs with Mlflow
import mlflow
import mlflow.sklearn

with mlflow.start_run():
    s = 'multiplicative' #seasonality_mode = ['additive', 'multiplicative']
    ss = 10        #seasonality_prior_scale = [0.01, 10], default = 10
    iw = 0.99      #interval_width = default=.80
    cs = 0.5       #changepoint_prior_scale = [0.001, 0.5] default = 0.05
    
    mall= Prophet(interval_width=iw, seasonality_mode=s,
                  seasonality_prior_scale = ss, changepoint_prior_scale = cs)
    mall.fit(hlallp)

    future_pd = mall.make_future_dataframe(
        periods=1440,
        freq='min',
        include_history=True
    )

    forecast = mall.predict(future_pd)
    forecasted = forecast.merge(hlallp, how='left', on='ds')
    forecasted['anomaly'] = 0
    forecasted.loc[forecasted['y'] > forecasted['yhat_upper'], 'anomaly'] = 1
    forecasted.loc[forecasted['y'] < forecasted['yhat_lower'], 'anomaly'] = -1
    anomaly = len(forecasted[forecasted['anomaly'] !=0])/len(forecasted)
    
    mlflow.log_metric("Anomalies", anomaly)
    mlflow.sklearn.log_model(mall, "Malware detection model")
    mlflow.log_param("seasonality_mode", s)
    mlflow.log_param("seasonality_prior_scale", ss)
    mlflow.log_param("changepoint_prior_scale", cs)
    mlflow.log_param("interval_width", iw)

# COMMAND ----------

# DBTITLE 1,Load Model from Mlflow registry for forecasting
logged_model = 'runs:/fd20d303c5f64008883e1e11e23ed797/Malware detection model'

# Load model as a PyFuncModel.
loaded_model = mlflow.pyfunc.load_model(logged_model)

# Predict on a Pandas DataFrame.
forecast = loaded_model.predict(future_pd)
forecasted = forecast.merge(hlallp, how='left', on='ds')
forecasted['anomaly'] = 0
forecasted.loc[forecasted['y'] > forecasted['yhat_upper'], 'anomaly'] = 1
forecasted.loc[forecasted['y'] < forecasted['yhat_lower'], 'anomaly'] = -1

# Plot the forecast and actuals/anomalies
fig = plt.figure(facecolor='w', figsize=(16,6))
ax = fig.add_subplot(111)
fcst = forecasted['ds'].dt.to_pydatetime()
ax.plot(mall.history[mall.history['y'] <= 50000]['ds'].dt.to_pydatetime(), mall.history[mall.history['y'] <= 50000]['y'], 'k.')
ax.plot(forecasted[(forecasted['anomaly'] !=0) & (forecasted['y'] <=50000)]['ds'], forecasted[(forecasted['anomaly'] != 0) & (forecasted['y'] <=50000)]['y'], 'r.')
ax.plot(fcst, forecasted['yhat'], ls='-', c='#0072B2')
if 'cap' in forecasted:
    ax.plot(fcst_t, fcst['cap'], ls='--', c='k')
if 'floor' in forecasted:
    ax.plot(fcst, forecasted['floor'], ls='--', c='k')
if True:
    ax.fill_between(fcst, forecasted['yhat_lower'], forecasted['yhat_upper'], \
                        color='#0072B2', alpha=0.2)
ax.grid(True, which='major', c='gray', ls='-', lw=1, alpha=0.2)
ax.set_xlabel("Minute")
ax.set_ylabel("Count")
fig.tight_layout()

# COMMAND ----------

mall.plot_components(forecast)

# COMMAND ----------

# DBTITLE 1,Calculate elapsed time for each process
#Calculate elapsed time for each process
dfhl2 = dfall.select('LogHost', 'ProcessID', 'ProcessName', (dfall.Time/60 +1).cast('int').alias('Time')).where(dfall.EventID == 4689)
hlall.createOrReplaceTempView("dfhl1")
dfhl2.createOrReplaceTempView("dfhl2")

# COMMAND ----------

dfhl2.show()

# COMMAND ----------

dfhl3 = spark.sql("select s.LogHost, s.ProcessID, s.ProcessName, s.Time as start, e.Time as end from dfhl1 s, dfhl2 e where \
          s.LogHost = e.LogHost and s.ProcessID = e.ProcessID and s.ProcessName = e.ProcessName and s.Time < e.Time")

# COMMAND ----------

dfhl3.createOrReplaceTempView("dfhl3")

# COMMAND ----------

dfhl4 = spark.sql("select *, (end - start) as dur from dfhl3")

# COMMAND ----------

dfhl4.write.saveAsTable("all_dur")

# COMMAND ----------

# MAGIC %r
# MAGIC library(SparkR)
# MAGIC df1 <- as.data.frame(sql("select * from all_dur"))

# COMMAND ----------

# MAGIC %r
# MAGIC summary(df1)
# MAGIC ggplot(data=df1) +geom_jitter(mapping=aes(x=start, y=dur), color='blue', size=1) + theme_classic() + facet_wrap(~ProcessName) +
# MAGIC   labs(x='Start Time(Minute)', y='Duration (seconds)')

# COMMAND ----------

# DBTITLE 1,Grouping by host name
hlcomp = hlall.groupBy("LogHost", "Time").count().toPandas()
hlcomp['ds'] = pd.to_datetime(hlcomp['Time'], unit='m')
hlcomp['y']  = hlcomp['count']

# COMMAND ----------

def comphl(hlcmp1):
    mcomp = Prophet(interval_width=iw, seasonality_mode=s,
                      seasonality_prior_scale = ss, changepoint_prior_scale = cs)
    mcomp.fit(hlcmp1)
    future = mcomp.make_future_dataframe(
        periods=1440,
        freq='min',
        include_history=True
    )
    forecast = mcomp.predict(future)
    forecasted = forecast.merge(hlcmp1, how='left', on='ds')
    forecasted['anomaly'] = 0
    forecasted.loc[forecasted['y'] > forecasted['yhat_upper'], 'anomaly'] = 1
    forecasted.loc[forecasted['y'] < forecasted['yhat_lower'], 'anomaly'] = -1
    anomaly = len(forecasted[forecasted['anomaly'] !=0])/len(forecasted)

    # Plot the forecast and actuals/anomalies
    fig = plt.figure(facecolor='w', figsize=(16,6))
    ax = fig.add_subplot(111)
    fcst = forecasted['ds'].dt.to_pydatetime()
    ax.plot(mcomp.history['ds'].dt.to_pydatetime(), mcomp.history['y'], 'k.')
    ax.plot(forecasted[(forecasted['anomaly'] !=0)]['ds'], forecasted[(forecasted['anomaly'] != 0)]['y'], 'r.')
    ax.plot(fcst, forecasted['yhat'], ls='-', c='#0072B2')
    if 'cap' in forecasted:
        ax.plot(fcst_t, fcst['cap'], ls='--', c='k')
    if 'floor' in forecasted:
        ax.plot(fcst, forecasted['floor'], ls='--', c='k')
    if True:
        ax.fill_between(fcst, forecasted['yhat_lower'], forecasted['yhat_upper'], \
                            color='#0072B2', alpha=0.2)
    ax.grid(True, which='major', c='gray', ls='-', lw=1, alpha=0.2)
    ax.set_xlabel("Minute")
    ax.set_ylabel("Count")
    fig.tight_layout()
    return fig

# COMMAND ----------

# DBTITLE 1,Model for a general high traffic batch server
#Model for a general high traffic batch server
hlcmp1 = hlcomp[hlcomp['LogHost'] == 'Comp742450']
comphl(hlcmp1)

# COMMAND ----------

# DBTITLE 1,Model for an enterprise application server
#Model for an enterprise application server
hlcmp1 = hlcomp[hlcomp['LogHost'] == 'EnterpriseAppServer']
comphl(hlcmp1)
